{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importing Libraries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\",category=FutureWarning)\n",
    "import pandas as pd\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from nltk.stem import PorterStemmer\n",
    "from annoy import AnnoyIndex\n",
    "import pickle\n",
    "pd.set_option('display.max_columns', None)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading and creating the training datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset_link = \"https://www.kaggle.com/datasets/akshaypawar7/millions-of-movies\"\n",
    "data_df = pd.read_csv('../data/movies.csv', encoding='utf-8', low_memory=False)\n",
    "data_df = data_df[(data_df['title'].notna()) & (data_df['genres'].notna()) & (data_df['original_language'] == 'en') & (data_df['status'] == 'Released') & (data_df['runtime'] > 30) & (data_df['credits'].notna()) & ((data_df['backdrop_path'].notna()) | (data_df['poster_path'].notna()))]\n",
    "data_df.info()\n",
    "data_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_df = data_df[['id', 'title', 'genres', 'overview', 'tagline', 'credits', 'keywords', 'poster_path', 'backdrop_path', 'recommendations']]\n",
    "train_df = data_df.drop(columns=['recommendations'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Filling the missing values in the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fill null values\n",
    "# {'overview': 'missing', 'keywords': 'missing', 'tagline': 'missing'}\n",
    "train_df = train_df.fillna(value={'overview': 'missing', 'keywords': 'missing', 'tagline': 'missing'}).drop_duplicates()\n",
    "train_df['poster_path'] = train_df['poster_path'].fillna(train_df['backdrop_path'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Modifying the column data for the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['genres'] = train_df['genres'].str.replace(' ', '')\n",
    "train_df['tagline'] = train_df['tagline'].str.replace('.', '')\n",
    "train_df['keywords'] = train_df['keywords'].str.replace(' ', '')\n",
    "train_df['credits'] = train_df['credits'].str.replace(' ', '')\n",
    "train_df['title'] = train_df['title'].str.replace(':', '')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['genres'] = train_df['genres'].str.split('-')\n",
    "train_df['credits'] = train_df['credits'].str.split('-')\n",
    "train_df['keywords'] = train_df['keywords'].str.split('-')\n",
    "train_df['overview'] = train_df['overview'].str.split(' ')\n",
    "train_df['tagline'] = train_df['tagline'].str.split(' ')\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['genres'].iloc[:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df['tags'] = train_df['title'].str.split(' ') + train_df['genres'] + train_df['keywords'] + train_df['tagline'] + train_df['credits'] + train_df['overview']\n",
    "train_df['tags'] = train_df['tags'].apply(lambda x: \" \".join(x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df = train_df[['id', 'title', 'tags', 'genres', 'overview', 'tagline', 'credits', 'keywords', 'poster_path', 'backdrop_path']]\n",
    "train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x = train_df[['id', 'title', 'tags', 'credits', 'overview', 'poster_path', 'backdrop_path']]\n",
    "train_x = train_x.drop_duplicates(['title'], keep='first').reset_index(drop=True)\n",
    "train_x['tags'] = train_x['tags'].str.lower().str.replace(':','')\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Vectorization of the data and predicting the recommendations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ps = PorterStemmer()\n",
    "train_x['tags'] = train_x['tags'].apply(lambda x: \" \".join([ps.stem(word) for word in x.split()]))\n",
    "train_x.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv = CountVectorizer(encoding='utf-8', decode_error='ignore', lowercase=True, max_features=5000, stop_words='english')\n",
    "vectors = cv.fit_transform(train_x['tags']).toarray()\n",
    "print(vectors.shape)\n",
    "cv.get_feature_names_out().tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "annoy_index = AnnoyIndex(vectors.shape[1], 'angular')  # 'angular' distance for cosine similarity\n",
    "\n",
    "# Add movie vectors to the Annoy index\n",
    "for i, vector in enumerate(vectors):\n",
    "    annoy_index.add_item(i, vector)\n",
    "\n",
    "# Build the Annoy index\n",
    "num_trees = 10\n",
    "annoy_index.build(num_trees)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def recommend(df, movie_title):\n",
    "    number_of_recommendations = 10  # Number of nearest neighbors to retrieve\n",
    "    if movie_title not in df['title'].tolist(): return []\n",
    "    movie_index = df['title'].tolist().index(movie_title)\n",
    "    nearest_neighbors = annoy_index.get_nns_by_vector(vectors[movie_index].flatten(), number_of_recommendations, include_distances=True)\n",
    "\n",
    "    # Display the indices and distances of nearest neighbors\n",
    "    similar_movie_indices = nearest_neighbors[0]  # Indices of similar movies\n",
    "    similarity_scores = nearest_neighbors[1]  # Similarity scores (distances)\n",
    "    print(\"Similarity scores of [{}]:\".format(similar_movie_indices[0]), similarity_scores)\n",
    "    return df['id'].iloc[similar_movie_indices].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "movie_ids = recommend(train_x,'Iron Man')\n",
    "train_x[(train_x['id'].isin(movie_ids))]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "train_x.columns.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_x['recommendations'] = train_x['title'].apply(lambda x: recommend(df=train_x, movie_title=str(x)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_x.shape)\n",
    "print(train_x[(train_x['title'] == 'Iron Man')])\n",
    "train_x[train_x['id'].isin([1726, 474227, 270768, 408648, 204240,299537])]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the output data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_file_path = '../data/recommendations_data.pkl'\n",
    "pickle_file = open(file=output_file_path,mode='wb')\n",
    "pickle.dump(obj=train_x, file=pickle_file)\n",
    "pickle_file.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
